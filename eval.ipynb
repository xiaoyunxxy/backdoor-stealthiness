{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d946102",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# General-purpose imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0eecfa-0995-46a7-9aa1-d62a51b2e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "from itertools import product\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b9840",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fee17d",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7b9b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18377df",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CLASS = 0\n",
    "\n",
    "ATTACKS = [\n",
    "    \"badnet\",\n",
    "    \"blended\",\n",
    "    \"wanet\",\n",
    "    \"bpp\",\n",
    "    \"adaptive_patch\",\n",
    "    \"adaptive_blend\",\n",
    "    \"dfst\",\n",
    "    \"narcissus\",\n",
    "    \"grond\",\n",
    "    \"dfba\"\n",
    "]\n",
    "\n",
    "# resnet18 or vgg16\n",
    "MODEL_ARCH = \"resnet18\"\n",
    "\n",
    "# cifar10, cifar100 or imagenette\n",
    "DATASET = \"cifar10\"\n",
    "\n",
    "POISON_RATES = [\n",
    "    lambda atk: 0.007 if DATASET == \"cifar100\" and atk in [\"narcissus\", \"grond\"] else 0.05,\n",
    "    lambda _: 0.003\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268e41d",
   "metadata": {},
   "source": [
    "## Constants dependent on experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20 if DATASET == \"imagenette\" else 100\n",
    "\n",
    "# Highest poison rate when comparing or visualizing trainset stealthiness \n",
    "DEFAULT_POISON_RATE = POISON_RATES[0]\n",
    "\n",
    "# Below constants allow multiple datasets and model architectures to be compared at the same time\n",
    "# We use this for one input-space stealthiness experiment\n",
    "MODEL_ARCHITECTURES = [MODEL_ARCH]\n",
    "DATASETS = [DATASET]\n",
    "\n",
    "N_CLASSES_DICT = {\n",
    "    \"cifar10\": 10,\n",
    "    \"cifar100\": 100,\n",
    "    \"imagenette\": 10\n",
    "}\n",
    "\n",
    "IMG_SIZE_DICT = {\n",
    "    \"cifar10\": (32, 32),\n",
    "    \"cifar100\": (32, 32),\n",
    "    \"imagenette\": (80, 80)\n",
    "}\n",
    "\n",
    "# Which index to use when comparing poisoned images, for each dataset\n",
    "IMG_INDEX_DICT = {\n",
    "    \"cifar10\": {\n",
    "        \"train\": [3, 50, 72, -4],\n",
    "        \"test\": 4\n",
    "    },\n",
    "    \"cifar100\": {\n",
    "        \"train\": [1, 11, 15, 21],\n",
    "        \"test\": 206\n",
    "    },\n",
    "    \"imagenette\": {\n",
    "        \"train\": [2, 3, 12, 4],\n",
    "        \"test\": 17\n",
    "    }\n",
    "}\n",
    "\n",
    "ATK_PPRINT_DICT = {\n",
    "    \"badnet\": \"BadNets\",\n",
    "    \"blended\": \"Blend\",\n",
    "    \"wanet\": \"WaNet\",\n",
    "    \"bpp\": \"BppAttack\",\n",
    "    \"adaptive_patch\": \"Adap-Patch\",\n",
    "    \"adaptive_blend\": \"Adap-Blend\",\n",
    "    \"dfst\": \"DFST\",\n",
    "    \"dfba\": \"DFBA\",\n",
    "    \"narcissus\": \"Narcissus\",\n",
    "    \"grond\": \"Grond\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f97eaa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55052ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZATION_DICT = {\n",
    "    \"cifar10\": ([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]),\n",
    "    \"cifar100\": ([0.5071, 0.4865, 0.4409], [0.2673, 0.2564, 0.2762]),\n",
    "    \"imagenette\": ([0.4671, 0.4593, 0.4306], [0.2692, 0.2657, 0.2884])\n",
    "}\n",
    "\n",
    "TO_TENSOR_LIST = [T.ToImage(), T.ToDtype(torch.float32, scale=True)]\n",
    "TRANSFORM_DICT = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for split in [\"train\", \"test\", \"train_transformed\", \"test_transformed\"]:\n",
    "        transforms = []\n",
    "        img_size = IMG_SIZE_DICT[dataset]\n",
    "        \n",
    "        if split == \"train_transformed\":\n",
    "            transforms += [T.RandomCrop(img_size, 4), T.RandomRotation(10)]\n",
    "\n",
    "            if dataset == \"cifar10\":\n",
    "                transforms.append(T.RandomHorizontalFlip())\n",
    "\n",
    "        transforms += TO_TENSOR_LIST\n",
    "\n",
    "        # Different normalization per dataset\n",
    "        if \"transformed\" in split:\n",
    "            mean, std = NORMALIZATION_DICT[dataset]\n",
    "            normalize = T.Normalize(mean, std)\n",
    "            transforms.append(normalize)\n",
    "\n",
    "        TRANSFORM_DICT[f\"{dataset}_{split}\"] = T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ee622",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "RECORD_DIR = \"./record\"\n",
    "RESULT_DIR = \"./results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f07f5",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23cbcfd",
   "metadata": {},
   "source": [
    "## Benign Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imagenette(torchvision.datasets.VisionDataset):\n",
    "    \"\"\"Custom torchvision implementation of the Imagenette dataset.\n",
    "\n",
    "    Unlike the official torchvision implementation of this dataset, this class has a 'data' attribute, which contains tensors representing all images.\n",
    "    This way, our code can handle Imagenette the same way as CIFAR-10 and CIFAR-100, which already have a data attribute in their official torchvision implementation.\"\"\"\n",
    "\n",
    "    def __init__(self, root=None, train=True, transform=None, target_transform=None):\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        split = \"train\" if train else \"val\"\n",
    "        img_folder = torchvision.datasets.ImageFolder(os.path.join(self.root, split))\n",
    "\n",
    "        self.classes = ['tench', 'English springer', 'cassette player', 'chain saw', 'church', 'French horn', 'garbage truck', 'gas pump', 'golf ball', 'parachute']\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        for img_path, label in img_folder.samples:\n",
    "            img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "            if len(img.shape) != 3:\n",
    "                print(img_path)\n",
    "                \n",
    "            self.data.append(img)\n",
    "            self.targets.append(label)\n",
    "\n",
    "        self.data = np.stack(self.data)\n",
    "\n",
    "    # Copied from CIFAR-10(0) implementation\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "    \n",
    "    # Copied from CIFAR-10(0) implementation\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbcb52b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Backdoor Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackdoorDataset(Dataset):\n",
    "    def __init__(self, bd_dataset, classes, target_class, original_labels, poison_lookup, cross_lookup=None):\n",
    "        self.bd_dataset = bd_dataset\n",
    "        self.classes = classes\n",
    "        self.target_class = target_class\n",
    "        self.original_labels = original_labels\n",
    "        self.poison_lookup = poison_lookup\n",
    "        self.cross_lookup = cross_lookup\n",
    "\n",
    "        # Create the poisoned labels by copying the original labels, and setting the poisoned indices to the target class\n",
    "        self.poisoned_labels = self.original_labels.copy()\n",
    "        self.poisoned_labels[self.poison_lookup] = self.target_class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bd_dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.bd_dataset.__getitem__(index) \n",
    "    \n",
    "# Wrapper around BackdoorBench's utils.bd_dataset_v2.dataset_wrapper_with_transform\n",
    "class BackdoorBenchDataset(BackdoorDataset):\n",
    "    def __init__(self, bb_dataset, target_class, replace_transform=None):\n",
    "        classes = bb_dataset.wrapped_dataset.dataset.classes\n",
    "        original_labels = np.array(bb_dataset.wrapped_dataset.dataset.targets)\n",
    "        poison_lookup = bb_dataset.wrapped_dataset.poison_indicator == 1\n",
    "        cross_lookup = bb_dataset.wrapped_dataset.poison_indicator == 2\n",
    "\n",
    "        if replace_transform:\n",
    "            bb_dataset.wrap_img_transform = replace_transform\n",
    "\n",
    "        super().__init__(bb_dataset, classes, target_class, original_labels, poison_lookup, cross_lookup)\n",
    "\n",
    "    # BackdoorBench dataset returns more than just the image and label\n",
    "    def __getitem__(self, index):\n",
    "        img, bd_label, dataset_idx, poison_bit, clean_label = self.bd_dataset.__getitem__(index) \n",
    "                       \n",
    "        return img, bd_label\n",
    "\n",
    "# Convert Adap-Blend/Patch folder of poisoned images to BackdoorDataset child class  \n",
    "class AdapDataset(BackdoorDataset):\n",
    "    def __init__(self, bd_record_path, target_class, split, clean_dataset):\n",
    "        bd_dataset_path = os.path.join(bd_record_path, \"data\", split)\n",
    "        bd_dataset = copy.deepcopy(clean_dataset)\n",
    "\n",
    "        classes = clean_dataset.classes\n",
    "        original_labels = np.array(clean_dataset.targets)\n",
    "        n_samples = len(clean_dataset)\n",
    "\n",
    "        if split == \"train\":\n",
    "            poison_indices = torch.load(os.path.join(bd_record_path, \"poison_indices\"))\n",
    "            cover_indices = torch.load(os.path.join(bd_record_path, \"cover_indices\"))\n",
    "        else:\n",
    "            poison_indices = range(n_samples)\n",
    "            cover_indices = []\n",
    "\n",
    "        # Replace benign images by their poisoned/cross versions for the indices specified above\n",
    "        for i in np.concat([poison_indices, cover_indices]):\n",
    "            i = int(i)\n",
    "            img = Image.open(os.path.join(bd_dataset_path, f\"{i}.png\"))\n",
    "            bd_dataset.data[i] = np.asarray(img)\n",
    "\n",
    "            # Also set label to target class for poisoned images\n",
    "            if i in poison_indices:\n",
    "                bd_dataset.targets[i] = target_class\n",
    "\n",
    "        poison_lookup = np.array([i in poison_indices for i in range(n_samples)])\n",
    "        cross_lookup = np.array([i in cover_indices for i in range(n_samples)])\n",
    "\n",
    "        super().__init__(bd_dataset, classes, target_class, original_labels, poison_lookup, cross_lookup)\n",
    "\n",
    "# Convert DFST poison_data.pt file to BackdoorDataset child class\n",
    "class DFSTDataset(BackdoorDataset):\n",
    "    def __init__(self, bd_record_path, target_class, split, clean_dataset):\n",
    "        classes = clean_dataset.classes\n",
    "        original_labels = np.array(clean_dataset.targets)\n",
    "        n_samples = len(clean_dataset)\n",
    "        bd_dataset = copy.deepcopy(clean_dataset)\n",
    "        bd_dataset_path = os.path.join(bd_record_path, \"poison_data.pt\")\n",
    "\n",
    "        # DFST saves poisoned versions of each image that is not of the target class\n",
    "        poison_data = torch.load(bd_dataset_path, weights_only=False)\n",
    "        non_target_poisoned = poison_data[split]\n",
    "\n",
    "        if split == \"train\":\n",
    "            # DFST randomly chooses poisoned samples each batch and epoch and replaces them by poisoned images that are not of the target class\n",
    "            # These poisoned images are saved to a file\n",
    "            # We have modified the file to only include a subset of these images according to the poison rate, and have also saved their indices\n",
    "            poison_indices = poison_data[\"train_indices\"]\n",
    "\n",
    "            # Mapping from indices in the trainset without the target class to indices in the full trainset\n",
    "            true_indices = np.arange(n_samples)[original_labels != TARGET_CLASS].squeeze()\n",
    "        else:\n",
    "            # The testset is fully poisoned\n",
    "            poison_indices = range(n_samples)\n",
    "\n",
    "            # The clean testset also filters the target class, so we do not have to convert the indices\n",
    "            true_indices = poison_indices \n",
    "\n",
    "        # Initialize poison_lookup and cross_lookup\n",
    "        poison_lookup = np.full(n_samples, False) \n",
    "        cross_lookup = np.full(n_samples, False) \n",
    "\n",
    "        # Replace benign images by poisoned ones for the poisoned indices in the DFST file, and their corresponding true indices in the dataset\n",
    "        for i, poison_idx in enumerate(poison_indices):\n",
    "            true_idx = true_indices[poison_idx]\n",
    "            poison_lookup[true_idx] = True\n",
    "\n",
    "            # Get poisoned image, put it in the backdoor dataset and change its label to the target class\n",
    "            poisoned_img = non_target_poisoned[i]\n",
    "            bd_dataset.data[true_idx] = (poisoned_img * 255).permute(1, 2, 0).numpy()\n",
    "            bd_dataset.targets[true_idx] = target_class \n",
    "\n",
    "        super().__init__(bd_dataset, classes, target_class, original_labels, poison_lookup, cross_lookup)\n",
    "\n",
    "# Apply DFBA trigger to benign testset\n",
    "class DFBADataset(BackdoorDataset):\n",
    "    def __init__(self, clean_testset, target_class, delta, mask):\n",
    "        # Get arguments expected by BackdoorDataset\n",
    "        classes = clean_testset.classes\n",
    "        original_labels = np.array(clean_testset.targets) # Clean-label attack, so labels do not change\n",
    "        n_samples = len(clean_testset)\n",
    "        poison_lookup = np.full(n_samples, True)\n",
    "        cross_lookup = np.full(n_samples, False) \n",
    "        bd_testset = copy.deepcopy(clean_testset)\n",
    "\n",
    "        # Poison all test images\n",
    "        for i in range(n_samples):\n",
    "            # Make color channels first dimension instead of last in order to apply mask to the image\n",
    "            img = bd_testset.data[i].transpose(2, 0, 1)\n",
    "\n",
    "            # Combine image and trigger using mask\n",
    "            bd_img = img * (1 - mask) + (delta * 255) * mask\n",
    "\n",
    "            # Reverse reordering of dimensions\n",
    "            bd_testset.data[i] = bd_img.transpose(1, 2, 0)\n",
    "\n",
    "            # Set label of image to target class\n",
    "            bd_testset.targets[i] = target_class\n",
    "\n",
    "        super().__init__(bd_testset, classes, target_class, original_labels, poison_lookup, cross_lookup)\n",
    "\n",
    "# Add absolute path to ./grond to the system PATH to prevent error in class below\n",
    "grond_dir = os.path.abspath(\"./grond\")\n",
    "sys.path.append(grond_dir)\n",
    "from grond.poison_loader import POI, POI_TEST\n",
    "\n",
    "# Wrapper around Grond's POI, POI_TEST (abstraction of CIFAR10_POI, CIFAR10_POI_TEST for any dataset)\n",
    "class GrondDataset(BackdoorDataset):\n",
    "    def __init__(self, dataset, transform, target_class, record_path, train=True):\n",
    "        # Reconstruct poisoned dataset used in attack\n",
    "        if train:\n",
    "            poison_indices = torch.load(os.path.join(record_path, \"poison_indices.pth\"))   \n",
    "            poi_dataset = POI(dataset, root=os.path.join(DATA_DIR, dataset), \n",
    "                              poison_rate=None, # poison rate is unused as we pass poison_indices directly\n",
    "                              transform=transform, poison_indices=poison_indices,\n",
    "                              target_cls=target_class, upgd_path=record_path)\n",
    "        else:\n",
    "            poi_dataset = POI_TEST(dataset, root=os.path.join(DATA_DIR, dataset),\n",
    "                                   transform=transform, exclude_target=True,\n",
    "                                   target_cls=target_class, upgd_path=record_path)\n",
    "\n",
    "        # Get arguments expected by BackdoorDataset\n",
    "        classes = poi_dataset.cleanset.classes\n",
    "        original_labels = np.array(poi_dataset.targets) # Clean-label attack, so labels do not change\n",
    "        n_samples = len(poi_dataset)\n",
    "        poison_lookup = np.array([i in poison_indices for i in range(n_samples)]) if train else np.full(n_samples, True)\n",
    "        cross_lookup = np.full(n_samples, False) \n",
    "\n",
    "        super().__init__(poi_dataset, classes, target_class, original_labels, poison_lookup, cross_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba51aee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad40d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create benign test dataset by excluding samples of target class\n",
    "def filter_target_class(dataset, target_class):\n",
    "    targets_ndarray = np.array(dataset.targets)\n",
    "    non_target_class = targets_ndarray != target_class\n",
    "    dataset.data = dataset.data[non_target_class] \n",
    "    dataset.targets = list(np.array(dataset.targets)[non_target_class])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Feed inputs from dataset to the model in order to extract the predictions\n",
    "def extract_preds(model, dataset):\n",
    "    predictions = torch.tensor([])\n",
    "    dl = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    for in_batch, _ in iter(dl):\n",
    "        with torch.no_grad():\n",
    "            pred_batch = model.forward(in_batch.to(DEVICE, non_blocking=True))\n",
    "            predictions = torch.cat([predictions, pred_batch.cpu().argmax(dim=1)])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Feed inputs from dataset to the model in order to extract the predictions and features of the specified layer\n",
    "def extract_preds_and_features(model, dataset, penultimate=True):\n",
    "    predictions = torch.tensor([])\n",
    "    features = torch.tensor([])\n",
    "    dl = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    for in_batch, _ in iter(dl):\n",
    "        size = len(in_batch) # May be smaller than bs for final batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Get features from the penultimate layer\n",
    "            if penultimate:\n",
    "                pred_batch, feat_batch = model.forward(in_batch.to(DEVICE, non_blocking=True), return_features=True)\n",
    "                feat_batch = feat_batch.reshape(size, -1)\n",
    "            else: # Get features from the layer used to measure TAC in \"Towards Backdoor Stealthiness in Model Parameter Space\": https://arxiv.org/pdf/2501.05928v1\n",
    "                pred_batch, feat_batch = model.forward_all_features(in_batch.to(DEVICE, non_blocking=True))\n",
    "                feat_batch = feat_batch[-1]\n",
    "\n",
    "            features = torch.cat([features, feat_batch.cpu()])\n",
    "            predictions = torch.cat([predictions, pred_batch.cpu().argmax(dim=1)])\n",
    "\n",
    "    return predictions, features\n",
    "\n",
    "# Given the experiment variable values, create a string identifier to use when loading and saving experiment results\n",
    "def experiment_variable_identifier(model_arch, dataset, poison_rate):\n",
    "    if poison_rate == None:\n",
    "        return f\"{model_arch}_{dataset}_pNone\"\n",
    "    else:\n",
    "        poison_rate_str = \"-\".join(str(poison_rate).split(\".\")) # replace . by -\n",
    "        return f\"{model_arch}_{dataset}_p{poison_rate_str}\"\n",
    "    \n",
    "def list_intersection(a: list, b: list):\n",
    "    return list(set(a) & set(b))\n",
    "\n",
    "def dict_subset(dict, keys):\n",
    "    return {k: v for k, v in dict.items() if k in keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a6eb9",
   "metadata": {},
   "source": [
    "# Stealthiness Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba536c5",
   "metadata": {},
   "source": [
    "## Input-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0fede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation of all input-space stealthiness metrics used in the study.\n",
    "\n",
    "Each metric requires the parameters img1 and img2, which are tensors of shape Nx3xHxW, representing batches of N RGB images of size HxW.\n",
    "The metrics calculate the mean similarity over the two batches, and they can also be used for single images by passing tensors with N=1.\n",
    "\"\"\"\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "import lpips\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from scipy.special import rel_entr\n",
    "from imagehash import phash\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchmetrics.functional.image import spectral_angle_mapper\n",
    "\n",
    "# Load neural networks globally for faster metric calculation\n",
    "loss_fn = lpips.LPIPS(net=\"alex\", verbose=False).to(DEVICE, non_blocking=True)\n",
    "inception_v3 = torch.hub.load(\"pytorch/vision:v0.10.0\", \"inception_v3\", pretrained=True).to(DEVICE, non_blocking=True)\n",
    "inception_v3.eval()\n",
    "\n",
    "def lp_norm(p, imgs):\n",
    "    return np.mean([norm(img.flatten(), ord=p) for img in imgs])\n",
    "\n",
    "def l1_distance(img1, img2):\n",
    "    return lp_norm(1, img1 - img2)\n",
    "\n",
    "def l2_distance(img1, img2):\n",
    "    return lp_norm(2, img1 - img2)\n",
    "\n",
    "def linf_distance(img1, img2):\n",
    "    return lp_norm(np.inf, img1 - img2)\n",
    "\n",
    "def MSE(img1, img2):\n",
    "    return mean_squared_error(img1.flatten(), img2.flatten())\n",
    "\n",
    "def PSNR(img1, img2):\n",
    "    with np.errstate(divide=\"ignore\"): # Ignore divide by zero warnings which occur if img1 == img2\n",
    "        return peak_signal_noise_ratio(img1.numpy(), img2.numpy())\n",
    "\n",
    "def SSIM(img1, img2):\n",
    "    SSIM_per_image = lambda x, y: structural_similarity(x, y, data_range=1, channel_axis=0)\n",
    "    SSIM_values = np.array(list(map(SSIM_per_image, img1.numpy(), img2.numpy())))\n",
    "\n",
    "    return SSIM_values.mean()\n",
    "\n",
    "def pHash(img1, img2):\n",
    "    def pHash_per_image(x, y):\n",
    "        tensor_to_pil = T.ToPILImage()\n",
    "        pil1 = tensor_to_pil(x)\n",
    "        pil2 = tensor_to_pil(y)\n",
    "\n",
    "        hash1 = phash(pil1)\n",
    "        hash2 = phash(pil2)\n",
    "    \n",
    "        def hamming_distance(hash1, hash2):\n",
    "            def phash_to_bool_array(phash):\n",
    "                return phash.hash.flatten() # Convert 8x8 boolean representation of 64-bit hash to 1D array of length 64\n",
    "                \n",
    "            bool_array1 = phash_to_bool_array(hash1)\n",
    "            bool_array2 = phash_to_bool_array(hash2)\n",
    "\n",
    "            return np.where(bool_array1 != bool_array2)[0].size\n",
    "        \n",
    "        return (1 - (hamming_distance(hash1, hash2) / 64.0)) * 100\n",
    "    \n",
    "    pHash_values = np.array(list(map(pHash_per_image, img1, img2)))\n",
    "    \n",
    "    return pHash_values.mean()\n",
    "\n",
    "def LPIPS(img1, img2):\n",
    "    with torch.no_grad():\n",
    "        normalize = T.Normalize([0.5], [0.5]) # Normalization required by LPIPS\n",
    "        img1, img2 = img1.to(DEVICE, non_blocking=True), img2.to(DEVICE, non_blocking=True)\n",
    "        \n",
    "        return loss_fn.forward(normalize(img1), normalize(img2)).mean().item()\n",
    "\n",
    "def IS(img1, img2):\n",
    "    with torch.no_grad():\n",
    "        preprocess = T.Compose([\n",
    "            T.Resize(299), # Model expects 299x299 images\n",
    "            T.CenterCrop(299),\n",
    "            T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # Normalization required by Inception v3 model\n",
    "        ])\n",
    "               \n",
    "        out1 = inception_v3(preprocess(img1.to(DEVICE, non_blocking=True)))\n",
    "        out2 = inception_v3(preprocess(img2.to(DEVICE, non_blocking=True)))\n",
    "\n",
    "        # Apply softmax to turn Inception v3 output into probabilities\n",
    "        preds1 = softmax(out1, dim=1)\n",
    "        preds2 = softmax(out2, dim=1)\n",
    "        \n",
    "        return rel_entr(preds1.cpu().numpy(), preds2.cpu().numpy()).sum(axis=1).mean() # Relative entropy = Kullback-Leibler divergence\n",
    "\n",
    "def SAM(img1, img2):\n",
    "    # Reduce range of images from [0, 1] to [1e-8, 1], as 0 vectors can cause NaN result\n",
    "    img1_clamped = torch.clamp(img1, 1e-8, 1)\n",
    "    img2_clamped = torch.clamp(img2, 1e-8, 1)\n",
    "\n",
    "    return spectral_angle_mapper(img1_clamped, img2_clamped, reduction='elementwise_mean').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c647c8e",
   "metadata": {},
   "source": [
    "## Feature-space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47536d0",
   "metadata": {},
   "source": [
    "### Silhouette Score (SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c403f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "def create_tsne(trainset, feature_path, skip_misclassified=False, show_plot=False, save_dst=None):\n",
    "    # Load target-label predictions, features the train data indices they belong to from the specified file\n",
    "    feature_dict = torch.load(feature_path, weights_only=False)\n",
    "    predictions = feature_dict[\"predictions\"]\n",
    "    features = feature_dict[\"features\"]\n",
    "    target_label_indices = feature_dict[\"indices\"]\n",
    "    \n",
    "    # Optionally filter features corresponding to wrongly classified inputs\n",
    "    if skip_misclassified:\n",
    "        correctly_classified = predictions == trainset.poisoned_labels\n",
    "        features = features[correctly_classified]\n",
    "        target_label_indices = target_label_indices[correctly_classified]\n",
    "\n",
    "    # Perform dimensionality reduction on the extracted features\n",
    "    def reduce_feature_dimensionality(features):\n",
    "        return TSNE().fit_transform(features)\n",
    "\n",
    "    features_embedded = reduce_feature_dimensionality(features)\n",
    "\n",
    "    # Split the features with the target label into benign, poisoned and cross features, and return the poisoned boolean index array\n",
    "    def split_features(features, poison_lookup, cross_lookup, indices):\n",
    "        is_poisoned = poison_lookup[indices]\n",
    "        is_cross = cross_lookup[indices]\n",
    "        is_benign = np.logical_not(np.logical_or(is_poisoned, is_cross))\n",
    "\n",
    "        benign = features[is_benign]\n",
    "        poisoned = features[is_poisoned]\n",
    "        cross = features[is_cross]\n",
    "        \n",
    "        return benign, poisoned, cross, is_poisoned\n",
    "\n",
    "    features_benign, features_poisoned, features_cross, is_poisoned = split_features(features_embedded, trainset.poison_lookup, trainset.cross_lookup, target_label_indices)\n",
    "    gt_labels = trainset.original_labels[target_label_indices][is_poisoned]\n",
    "\n",
    "    # Visualize the latent separability of the model, styling from https://github.com/Unispac/Circumventing-Backdoor-Defenses/blob/master/visualize.py\n",
    "    def plot(features_benign, features_poisoned, features_cross, gt_labels, highlight_cross=False, groupby_gt=False, show_plot=False, save_dst=None):\n",
    "        def plot_benign(features):\n",
    "            plt.scatter(features[:, 0], features[:, 1], label=\"Benign\", marker='o', s=5, color=\"blue\", alpha=1.0)\n",
    "\n",
    "        # Plot cross samples separately if highlight_cross is true, otherwise consider them as benign samples\n",
    "        if highlight_cross:\n",
    "            plot_benign(features_benign)\n",
    "            plt.scatter(features_cross[:, 0], features_cross[:, 1], label=\"Cross\", marker='v', s=8, color='green', alpha=0.7)\n",
    "        else:\n",
    "            plot_benign(np.concat([features_benign, features_cross], axis=0))\n",
    "\n",
    "        # Group the poisoned features by their corresponding ground truth label, to show how each class forms a separate cluster \n",
    "        if groupby_gt:\n",
    "            class_colors = ['#ff001c', '#ff0055', '#ff008e', '#ff00c6', '#ff00ff', \n",
    "                            '#ff1c00', '#ff5500', '#ff8e00', '#ffc600', '#ffff00']\n",
    "\n",
    "            for i, c in enumerate(trainset.classes):\n",
    "                c_indices = gt_labels == i\n",
    "                c_features = features_poisoned[c_indices]\n",
    "                plt.scatter(c_features[:, 0], c_features[:, 1], label=f\"Poisoned ({c})\", marker='^', s=8, color=class_colors[i], alpha=0.7)\n",
    "        else:\n",
    "            plt.scatter(features_poisoned[:, 0], features_poisoned[:, 1], label=\"Poisoned\", marker='^', s=8, color=\"red\", alpha=0.7)\n",
    "            \n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_dst:\n",
    "            os.makedirs(save_dst, exist_ok=True)\n",
    "\n",
    "            # Add enabled visual options to filename\n",
    "            opts = np.array([highlight_cross, groupby_gt])\n",
    "            opts_str = np.array([\"highlight_cross\", \"groupby_gt\"])[opts]\n",
    "            if len(opts_str) > 0:\n",
    "                filename = f\"{'_'.join(opts_str)}\"\n",
    "            else:\n",
    "                filename = \"default\"\n",
    "\n",
    "            plt.savefig(os.path.join(save_dst, filename), transparent=True) \n",
    "\n",
    "        if show_plot:\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    if show_plot or save_dst:\n",
    "        # Create plots with various visual options\n",
    "        for highlight_cross, groupby_gt in product([False, True], [False, True]):\n",
    "            # Do not create plots highlighting cross samples if there are none\n",
    "            if highlight_cross and not np.any(trainset.cross_lookup):\n",
    "                continue\n",
    "\n",
    "            # Do not create plots highlighting each original classes of poisoned samples if there are too many classes\n",
    "            if groupby_gt and len(trainset.classes) != 10:\n",
    "                continue\n",
    "\n",
    "            plot(features_benign, features_poisoned, features_cross, gt_labels, highlight_cross, groupby_gt, show_plot, save_dst)\n",
    "\n",
    "    # Concatenate benign and cross features, since we consider cross samples to be benign\n",
    "    return np.concat([features_benign, features_cross]), features_poisoned, gt_labels\n",
    "\n",
    "def clustering_score(features_benign, features_poisoned, silhouette=True):\n",
    "    n_benign = len(features_benign)\n",
    "    n_poisoned = len(features_poisoned)\n",
    "    cluster_labels = np.concat([np.zeros(n_benign), np.ones(n_poisoned)])\n",
    "    features = np.concat([features_benign, features_poisoned])\n",
    "    \n",
    "    if silhouette:\n",
    "        return silhouette_score(features, cluster_labels)\n",
    "    else:\n",
    "        return davies_bouldin_score(features, cluster_labels)\n",
    "\n",
    "SS = lambda x, y: clustering_score(x, y, silhouette=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f05ced",
   "metadata": {},
   "source": [
    "### Class-specific Davies-Bouldin Index (DBI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13429dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Davies-Bouldin Index between the benign cluster and poisoned subcluster for each class\n",
    "def CDBI(features_benign, features_poisoned, gt_labels_poisoned):\n",
    "    total = 0\n",
    "    i = 0\n",
    "    n_classes = N_CLASSES_DICT[DATASET]\n",
    "    \n",
    "    for c in range(n_classes):    \n",
    "        c_indices = gt_labels_poisoned == c\n",
    "\n",
    "        # Skip classes for which there are no poisoned samples\n",
    "        # This happens for DFST (does not poison samples already of target class) and the clean-label attacks\n",
    "        if not np.any(c_indices):\n",
    "            continue\n",
    "\n",
    "        total += clustering_score(features_benign, features_poisoned[c_indices], silhouette=False)\n",
    "        i += 1\n",
    "\n",
    "    return total / i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8662a9f",
   "metadata": {},
   "source": [
    "### Discriminant Sliced-Wasserstein Distance (DWSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5315ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ot import wasserstein_1d\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def DSWD(model, feature_path, skip_misclassified=False):\n",
    "    final_layer_name = \"linear\" if MODEL_ARCH == \"resnet18\" else \"classifier\"\n",
    "    weights = model.state_dict()[f\"{final_layer_name}.weight\"].cpu()\n",
    "\n",
    "    # Load features from the specified file\n",
    "    feature_dict = torch.load(feature_path, weights_only=False)\n",
    "    features_clean = feature_dict[\"features_clean\"]\n",
    "    features_bd = feature_dict[\"features_bd\"]\n",
    "    predictions = feature_dict[\"predictions_bd\"]\n",
    "    \n",
    "    # Optionally filter features corresponding to wrongly classified inputs\n",
    "    if skip_misclassified:\n",
    "        correctly_classified = predictions == torch.full_like(predictions, TARGET_CLASS)\n",
    "        features_clean = features_clean[correctly_classified]\n",
    "        features_bd = features_bd[correctly_classified]\n",
    "\n",
    "    return DSWD_eq_7(features_clean, features_bd, weights)\n",
    "\n",
    "def DSWD_eq_7(features_clean, features_bd, param_matrix):\n",
    "    \"\"\"Implementation of Equation (7) of \\\"Backdoor Attack with Imperceptible Input and Latent Modification\\\".\n",
    "    Based on the unofficial implementation from https://github.com/RJ-T/Wasserstein-Backdoor/blob/master/lira_trigger_generation.py.\n",
    "    \n",
    "    Notation from the paper: \n",
    "     - N = dataset size;\n",
    "     - d = dimension of the latent space;\n",
    "     - C = set of classes.\n",
    "\n",
    "    :param features_clean: N x d matrix F_c\n",
    "    :param features_bd: N x d matrix F_b\n",
    "    :param param_matrix: |C| x d matrix W between the penultimate and the output layers\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize each row of the parameter matrix using L2 norm\n",
    "    param_matrix_norm = normalize(param_matrix, axis=1)\n",
    "    \n",
    "    # Transpose features to multiply them with rows of the parameter matrix\n",
    "    features_clean = features_clean.T\n",
    "    features_bd = features_bd.T\n",
    "    projected_features_clean = np.matmul(param_matrix_norm, features_clean.numpy())\n",
    "    projected_features_bd = np.matmul(param_matrix_norm, features_bd.numpy())\n",
    "\n",
    "    # Summation in Equation 7\n",
    "    classes = range(len(param_matrix))\n",
    "    sum = np.sum([wasserstein_1d(projected_features_clean[c], projected_features_bd[c], p=2) for c in classes]) # wasserstein_1d(p=2) returns Wasserstein-2 distance raised to the power of 2\n",
    "    \n",
    "    # Divide by |C| and take square root\n",
    "    dswd = (sum / len(classes))**0.5\n",
    "\n",
    "    return dswd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f9fc1",
   "metadata": {},
   "source": [
    "## Parameter-space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6f1db",
   "metadata": {},
   "source": [
    "### Upper bound of the Channel Lipschitzness Constant (UCLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UCLC(model, normalize=True): \n",
    "    \"\"\"Based on the official implementation of Channel Lipschitzness-based Pruning: \n",
    "    https://github.com/rkteddy/channel-Lipschitzness-based-pruning/blob/main/defense.py.\"\"\"\n",
    "    \n",
    "    uclc = torch.Tensor([])\n",
    "    \n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            std = m.running_var.sqrt()\n",
    "            weight = m.weight\n",
    "\n",
    "            channel_lips = []\n",
    "            for idx in range(weight.shape[0]):\n",
    "                # Combining weights of convolutions and BN\n",
    "                w = conv.weight[idx].reshape(conv.weight.shape[1], -1) * (weight[idx]/std[idx]).abs()\n",
    "                channel_lips.append(torch.svd(w.cpu())[1].max())\n",
    "            channel_lips = torch.Tensor(channel_lips)\n",
    "\n",
    "            if normalize:\n",
    "                channel_lips = (channel_lips - channel_lips.mean()) / channel_lips.std()\n",
    "\n",
    "            uclc = torch.cat((uclc, channel_lips))\n",
    "        \n",
    "       # Convolutional layer should be followed by a BN layer by default\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            conv = m\n",
    "\n",
    "    # Return the maximum deviation factor, as this indicates the channel with highest sensitivity, which is likely backdoored\n",
    "    return uclc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd17406",
   "metadata": {},
   "source": [
    "### Trigger-Activated Change (TAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TAC(tac_path, bd_or_clean=\"bd\", skip_misclassified=False):\n",
    "    # Load input-wise TAC from the specified file\n",
    "    tac_dict = torch.load(tac_path, weights_only=False)\n",
    "    tac_per_input = tac_dict[bd_or_clean][\"tac\"]\n",
    "    predictions = tac_dict[bd_or_clean][\"predictions_bd\"]\n",
    "\n",
    "    if skip_misclassified:\n",
    "        correctly_classified = predictions == torch.full_like(predictions, TARGET_CLASS)\n",
    "        tac_per_input = tac_per_input[correctly_classified]\n",
    "\n",
    "    # Calculate average over all inputs\n",
    "    return tac_per_input.mean(dim=0)\n",
    "\n",
    "def TAC_comparison(record_dict, model_arch, dataset):  \n",
    "    def plot_TAC(tac_save_path, ax, atk, pr):\n",
    "        # Pretty printed attack name\n",
    "        bd_label = f\"{ATK_PPRINT_DICT[atk]}\"\n",
    "\n",
    "        # Add poisoning rate if applicable\n",
    "        if pr:\n",
    "            bd_label += f\" {pr*100:g}% PR\"\n",
    "\n",
    "        # Calculate and plot TAC for both the backdoored model and a benign model for comparison\n",
    "        for desc in [\"bd\", \"clean\"]:\n",
    "            tac = TAC(tac_save_path, desc)\n",
    "            label = \"Benign\" if desc == \"clean\" else bd_label\n",
    "            color = \"blue\" if desc == \"clean\" else \"red\"\n",
    "\n",
    "            ax.scatter(range(len(tac)), np.sort(tac), label=label, s=4, color=color, alpha=0.7)\n",
    "            ax.legend(loc=\"upper left\")\n",
    "\n",
    "            # Logarithmic scale necessary due to huge maximum TAC of DFBA\n",
    "            ax.set_yscale('log')\n",
    "\n",
    "    # More attacks to evaluate in ResNet18, so we divide them over two rows\n",
    "    row_multiplier = 2 if MODEL_ARCH == \"resnet18\" else 1\n",
    "\n",
    "    n_rows = row_multiplier * len(POISON_RATES)\n",
    "    n_plots = len(ATTACKS) * len(POISON_RATES)\n",
    "    n_cols = n_plots  // n_rows\n",
    "    fig, ax = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, squeeze=False)\n",
    "    fig.set_figheight(2.5 * n_rows)\n",
    "    fig.set_figwidth(3.5 * n_cols)\n",
    "    exp_id = f\"{model_arch}_{dataset}\"\n",
    "\n",
    "    for i, atk in enumerate(ATTACKS):\n",
    "        col_idx = i % n_cols\n",
    "        row_idx = 0 if i < n_cols else len(POISON_RATES)\n",
    "        atk_dict = record_dict[model_arch][dataset][atk]\n",
    "\n",
    "        if atk == \"dfba\":\n",
    "            tac_save_path = os.path.join(RESULT_DIR, \"tac_activations\", exp_id, f\"{atk}.pt\")\n",
    "            plot_TAC(tac_save_path, ax[row_idx][col_idx], atk, None)\n",
    "\n",
    "            if len(POISON_RATES) > 1:\n",
    "                # Delete unused axis\n",
    "                fig.delaxes(ax[row_idx+1][col_idx])\n",
    "        else:\n",
    "            poison_rates = atk_dict.keys()\n",
    "\n",
    "            for j, pr in enumerate(poison_rates):\n",
    "                tac_save_path = os.path.join(RESULT_DIR, \"tac_activations\", exp_id, f\"{atk}_p{pr}.pt\")\n",
    "                plot_TAC(tac_save_path, ax[row_idx + j][col_idx], atk, pr)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    save_path = os.path.join(RESULT_DIR, \"tac_activations\", exp_id, \"TAC_comparison.png\")\n",
    "    fig.savefig(save_path, dpi=300)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31854730",
   "metadata": {},
   "source": [
    "### TAC-UCLC Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31436986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TUP(tac_path, model_bd):\n",
    "    # Average TAC over all inputs for the backdoored and benign model\n",
    "    tac_bd = TAC(tac_path, bd_or_clean=\"bd\")\n",
    "    tac_clean = TAC(tac_path, bd_or_clean=\"clean\")\n",
    "\n",
    "    # Sort the backdoored and benign model's TAC separately. remember the sorting indices for the former model\n",
    "    bd_indices = np.argsort(tac_bd)\n",
    "    tac_bd = tac_bd[bd_indices]\n",
    "    tac_clean = np.sort(tac_clean)\n",
    "\n",
    "    # Calculate the ratio between backdoored and benign model TAC\n",
    "    tac_ratio = tac_bd / tac_clean\n",
    "\n",
    "    # TAC is based on the batch normalization layer before the adaptive average pooling layer\n",
    "    # To calculate UCLC on the same layer, we additionally require the convolutional layer before it\n",
    "    if MODEL_ARCH == \"resnet18\":\n",
    "        model_bd = model_bd.layer4[1] \n",
    "        model_bd = nn.Sequential(model_bd.conv2, model_bd.bn2)\n",
    "    else:\n",
    "        model_bd = model_bd.features[-5:-3]\n",
    "\n",
    "    # Calculate UCLC of the backdoored model and put neurons in the same order as the backdoored TAC values \n",
    "    uclc_bd = UCLC(model_bd, normalize=False)[bd_indices]\n",
    "\n",
    "    return np.average(uclc_bd * tac_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee43bff2",
   "metadata": {},
   "source": [
    "# Benign/backdoored data and models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02b576",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add absolute path to ./backdoorbench to the system PATH in order to import backdoorbench functions\n",
    "bb_dir = os.path.abspath(\"./backdoorbench\")\n",
    "sys.path.append(bb_dir)\n",
    "from backdoorbench.models.resnet import ResNet18\n",
    "from backdoorbench.models.vgg import VGG16\n",
    "from backdoorbench.utils.save_load_attack import load_attack_result\n",
    "\n",
    "def get_dataset(dataset, train=True, transforms=None):\n",
    "    data_root = os.path.join(DATA_DIR, dataset)\n",
    "\n",
    "    if dataset == \"cifar10\":\n",
    "        return torchvision.datasets.CIFAR10(root=data_root, \n",
    "                                            train=train, \n",
    "                                            download=True,\n",
    "                                            transform=transforms)\n",
    "    elif dataset == \"cifar100\":\n",
    "        return torchvision.datasets.CIFAR100(root=data_root, \n",
    "                                             train=train, \n",
    "                                             download=True,\n",
    "                                             transform=transforms)\n",
    "    else:\n",
    "        return Imagenette(root=data_root, \n",
    "                          train=train,\n",
    "                          transform=transforms)\n",
    "\n",
    "def load_model_state(arch, dataset, state_dict):\n",
    "    if arch == \"resnet18\":\n",
    "        model = ResNet18(num_classes=N_CLASSES_DICT[dataset]).to(DEVICE, non_blocking=True)\n",
    "    elif arch == \"vgg16\":\n",
    "        model = VGG16(num_classes=N_CLASSES_DICT[dataset]).to(DEVICE, non_blocking=True)\n",
    "    else:\n",
    "        raise Exception(\"Architecture not supported\")\n",
    "    \n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model.to(DEVICE, non_blocking=True)\n",
    "\n",
    "def load_clean_record(dataset, arch):\n",
    "    record = {}\n",
    "\n",
    "    # Get datasets\n",
    "    for key in [\"train\", \"test\", \"train_transformed\", \"test_transformed\"]:\n",
    "        record[key] = get_dataset(dataset, train=\"train\" in key, transforms=TRANSFORM_DICT[f\"{dataset}_{key}\"])\n",
    "\n",
    "        # Filter target class out of test datasets\n",
    "        if key in [\"test\", \"test_transformed\"]:\n",
    "            record[key] = filter_target_class(record[key], TARGET_CLASS)\n",
    "\n",
    "    # Load dictionary containing model state dict\n",
    "    clean_path = os.path.join(RECORD_DIR,\n",
    "                              f\"prototype_{experiment_variable_identifier(arch, dataset, None)}\",\n",
    "                              \"clean_model.pth\")\n",
    "    state_dict = torch.load(clean_path)\n",
    "    record[\"model\"] = load_model_state(arch, dataset, state_dict)\n",
    "\n",
    "    return record\n",
    "\n",
    "def load_backdoor_record(dataset, arch, atk, poison_rate, clean_record):\n",
    "    atk_path = os.path.join(RECORD_DIR,\n",
    "                            f\"{atk}_{experiment_variable_identifier(arch, dataset, poison_rate)}\")\n",
    "\n",
    "    # Different attack implementations use different functions \n",
    "    if atk in [\"badnet\", \"blended\", \"wanet\", \"bpp\", \"narcissus\"]:\n",
    "        return load_backdoorbench(atk, atk_path, dataset, arch)\n",
    "    elif atk in [\"adaptive_patch\", \"adaptive_blend\", ]:\n",
    "        return load_adap(atk_path, dataset, arch, clean_record)\n",
    "    elif atk == \"dfst\":\n",
    "        return load_dfst(atk_path, dataset, arch, clean_record)\n",
    "    elif atk == \"grond\":\n",
    "        return load_grond(atk_path, dataset, arch)\n",
    "    elif atk == \"dfba\":\n",
    "        return load_dfba(atk_path, dataset, arch, clean_record)\n",
    "    else:\n",
    "        raise Exception(f\"{atk} is not supported\")\n",
    "    \n",
    "def load_backdoorbench(atk, atk_path, dataset, arch):\n",
    "    record = {}\n",
    "    atk_result = load_attack_result(os.path.join(atk_path, \"attack_result.pt\"))\n",
    "\n",
    "    # Load backdoored data\n",
    "    for key in [\"train\", \"test\", \"train_transformed\", \"test_transformed\"]:\n",
    "        key_until_underscore = key.split('_')[0]\n",
    "        bd_dataset = copy.deepcopy(atk_result[f\"bd_{key_until_underscore}\"])\n",
    "        \n",
    "        # Only narcissus needs an untransformed trainset to compare its asymmetric trigger\n",
    "        if key == \"train\" and atk != \"narcissus\":\n",
    "            continue\n",
    "        \n",
    "        # replace_transform removes the existing normalization for train and test keys\n",
    "        record[key] = BackdoorBenchDataset(bd_dataset, TARGET_CLASS, \n",
    "                                           replace_transform=TRANSFORM_DICT[f\"{dataset}_{key}\"])\n",
    "\n",
    "    record[\"model\"] = load_model_state(arch, dataset, atk_result[\"model\"])\n",
    "\n",
    "    return record\n",
    "\n",
    "def load_adap(atk_path, dataset, arch, clean_record):\n",
    "    record = {}\n",
    "\n",
    "    # Load backdoored data\n",
    "    for key in [\"train\", \"test\", \"train_transformed\", \"test_transformed\"]:\n",
    "        key_until_underscore = key.split('_')[0]\n",
    "        record[key] = AdapDataset(atk_path, TARGET_CLASS, \n",
    "                                  key_until_underscore, clean_record[key])\n",
    "    \n",
    "    state_dict = torch.load(os.path.join(atk_path, \"model.pt\"), map_location=DEVICE)\n",
    "    record[\"model\"] = load_model_state(arch, dataset, state_dict)\n",
    "\n",
    "    return record\n",
    "\n",
    "def load_dfst(atk_path, dataset, arch, clean_record):\n",
    "    record = {}\n",
    "\n",
    "    # Load backdoored data\n",
    "    for key in [\"test\", \"train_transformed\", \"test_transformed\"]:\n",
    "        key_until_underscore = key.split('_')[0]\n",
    "        record[key] = DFSTDataset(atk_path, TARGET_CLASS, \n",
    "                                  key_until_underscore, clean_record[key])\n",
    "\n",
    "    state_dict = torch.load(os.path.join(atk_path, \"model.pt\"), map_location=DEVICE, weights_only=False)\n",
    "    record[\"model\"] = load_model_state(arch, dataset, state_dict)\n",
    "\n",
    "    return record\n",
    "\n",
    "def load_dfba(atk_path, dataset, arch, clean_record):\n",
    "    record = {}\n",
    "\n",
    "    # Load trigger, consisting of a mask and perturbation delta\n",
    "    mask = torch.load(os.path.join(atk_path, \"mask.pth\"), weights_only=False)\n",
    "    delta = torch.load(os.path.join(atk_path, \"delta.pth\"), weights_only=False)\n",
    "    \n",
    "    # Load backdoored test data (no train data available since attack is data-free)\n",
    "    for key in [\"test\", \"test_transformed\"]:\n",
    "        record[key] = DFBADataset(clean_record[key], TARGET_CLASS, \n",
    "                                  delta, mask)\n",
    "    \n",
    "    state_dict = torch.load(os.path.join(atk_path, \"model.pth\"), map_location=DEVICE)\n",
    "    record[\"model\"] = load_model_state(arch, dataset, state_dict)\n",
    "\n",
    "    return record\n",
    "\n",
    "def load_grond(atk_path, dataset, arch):\n",
    "    record = {}\n",
    "\n",
    "    # Load backdoored data\n",
    "    for key in [\"test\", \"train_transformed\", \"test_transformed\"]:\n",
    "        record[key] = GrondDataset(dataset, TRANSFORM_DICT[f\"{dataset}_{key}\"], TARGET_CLASS, atk_path, \"train\" in key)\n",
    "\n",
    "    checkpoint = torch.load(os.path.join(atk_path, \"checkpoint.pth\"), map_location=DEVICE)\n",
    "    state_dict = checkpoint[\"model\"]\n",
    "    record[\"model\"] = load_model_state(arch, dataset, state_dict)\n",
    "\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572cbfb",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9cf7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the benign and backdoored records (data & models) in a dictionary\n",
    "record_dict = {}\n",
    "\n",
    "for arch in MODEL_ARCHITECTURES:\n",
    "    record_dict[arch] = {}\n",
    "\n",
    "    for dataset in DATASETS:\n",
    "        record_dict[arch][dataset] = {}\n",
    "        record_dict[arch][dataset][\"prototype\"] = load_clean_record(dataset, arch)\n",
    "\n",
    "        for atk in ATTACKS:\n",
    "            print(atk)\n",
    "            record_dict[arch][dataset][atk] = {}\n",
    "\n",
    "            # DFBA is data-free, so we do not need to divide its record per poison rate\n",
    "            if atk == \"dfba\":\n",
    "                record_dict[arch][dataset][atk] = load_backdoor_record(dataset, arch, atk, None, record_dict[arch][dataset][\"prototype\"])\n",
    "                continue\n",
    "\n",
    "            for pr_function in POISON_RATES:\n",
    "                pr = pr_function(atk)\n",
    "                record_dict[arch][dataset][atk][pr] = load_backdoor_record(dataset, arch, atk, pr, record_dict[arch][dataset][\"prototype\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770cc74",
   "metadata": {},
   "source": [
    "# Attack evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c9bd14",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0156e",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11593d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_size(eval_type):\n",
    "    # Evaluate all samples on GPU\n",
    "    if DEVICE.type == \"cuda\": \n",
    "        return None\n",
    "\n",
    "    # Otherwise, evaluate an appropiately sized sample \n",
    "    if eval_type == \"input\":\n",
    "        return 10\n",
    "    elif eval_type == \"model\":\n",
    "        return 100\n",
    "    else:\n",
    "        raise Exception(\"Evaluation type unknown\")\n",
    "    \n",
    "def save_train_feature_space(atk_id, model, trainset, path, sample_size=None):\n",
    "    # Only save trainset features of the target class\n",
    "    original_target_label = trainset.original_labels == trainset.target_class\n",
    "    target_label_indices = np.argwhere(np.logical_or(original_target_label, trainset.poison_lookup)).squeeze()\n",
    "    \n",
    "    if sample_size:\n",
    "        target_label_indices = np.random.choice(target_label_indices, size=sample_size, replace=False)\n",
    "\n",
    "    subset = torch.utils.data.Subset(trainset, target_label_indices)\n",
    "    preds, features = extract_preds_and_features(model, subset)\n",
    "\n",
    "    train_features = {\n",
    "        \"features\": features,\n",
    "        \"predictions\": preds,\n",
    "        \"indices\": target_label_indices\n",
    "    }\n",
    "    torch.save(train_features, os.path.join(path, atk_id))\n",
    "    \n",
    "\n",
    "def save_clean_test_preds_all_labels(atk_id, model, testset_clean, path, sample_size=None):\n",
    "    sample_indices = np.array(range(len(testset_clean)))\n",
    "    \n",
    "    if sample_size:\n",
    "        sample_indices = np.random.choice(sample_indices, size=sample_size, replace=False)\n",
    "        testset_clean = torch.utils.data.Subset(testset_clean, sample_indices)\n",
    "\n",
    "    preds_clean = extract_preds(model, testset_clean)\n",
    "   \n",
    "    test_features = {\n",
    "        \"predictions_clean\": preds_clean,\n",
    "        \"indices\": sample_indices\n",
    "    }\n",
    "    torch.save(test_features, os.path.join(path, atk_id))\n",
    "\n",
    "def save_test_feature_space(atk_id, model, testset_clean, testset_bd, path, sample_size=None):\n",
    "    sample_indices = np.array(range(len(testset_clean)))\n",
    "    \n",
    "    if sample_size:\n",
    "        sample_indices = np.random.choice(sample_indices, size=sample_size, replace=False)\n",
    "        testset_clean = torch.utils.data.Subset(testset_clean, sample_indices)\n",
    "        testset_bd = torch.utils.data.Subset(testset_bd, sample_indices)\n",
    "\n",
    "    preds_clean, features_clean = extract_preds_and_features(model, testset_clean)\n",
    "    preds_bd, features_bd = extract_preds_and_features(model, testset_bd)\n",
    "\n",
    "    test_features = {\n",
    "        \"features_clean\": features_clean,\n",
    "        \"features_bd\": features_bd,\n",
    "        \"predictions_clean\": preds_clean,\n",
    "        \"predictions_bd\": preds_bd,\n",
    "        \"indices\": sample_indices\n",
    "    }\n",
    "    torch.save(test_features, os.path.join(path, atk_id))\n",
    "\n",
    "def save_tac_activations(atk_id, model_clean, model_bd, testset_clean, testset_bd, path, sample_size=None):\n",
    "    sample_indices = np.array(range(len(testset_clean)))\n",
    "    \n",
    "    if sample_size:\n",
    "        sample_indices = np.random.choice(sample_indices, size=sample_size, replace=False)\n",
    "        testset_clean = torch.utils.data.Subset(testset_clean, sample_indices)\n",
    "        testset_bd = torch.utils.data.Subset(testset_bd, sample_indices)\n",
    "\n",
    "    test_features = {\n",
    "        \"indices\": sample_indices\n",
    "    }\n",
    "\n",
    "    # We extract features both with a benign and backdoored model, in order to compare their TAC values\n",
    "    for model, desc in zip([model_clean, model_bd], [\"clean\", \"bd\"]):\n",
    "        # To measure TAC, we extract features from a layer other than the penultimate layer\n",
    "        preds_clean, features_clean = extract_preds_and_features(model, testset_clean, penultimate=False)\n",
    "        preds_bd, features_bd = extract_preds_and_features(model, testset_bd, penultimate=False)\n",
    "\n",
    "        diff = features_clean - features_bd\n",
    "\n",
    "        # diff dimensions = number of inputs X amount of neurons in layer X kernel height X kernel width\n",
    "        tac_per_input = torch.norm(diff, dim=(2,3)) \n",
    "\n",
    "        test_features[desc] = {\n",
    "            \"tac\": tac_per_input,\n",
    "            \"predictions_clean\": preds_clean,\n",
    "            \"predictions_bd\": preds_bd,\n",
    "        }\n",
    "\n",
    "    torch.save(test_features, os.path.join(path, atk_id))\n",
    "\n",
    "def save_tsne(atk_id, trainset, feature_train_path, path):\n",
    "    feature_train_path = os.path.join(feature_train_path, f\"{atk_id}.pt\")\n",
    "    save_dir = os.path.join(path, atk_id)\n",
    "    features_benign, features_poisoned, gt_labels_poisoned = create_tsne(trainset, feature_train_path, save_dst=save_dir)\n",
    "    \n",
    "    tsne = {\n",
    "        \"features_benign\": features_benign,\n",
    "        \"features_poisoned\": features_poisoned,\n",
    "        \"gt_labels_poisoned\": gt_labels_poisoned\n",
    "    }\n",
    "\n",
    "    torch.save(tsne, os.path.join(save_dir, \"embedding.pt\"))\n",
    "\n",
    "\n",
    "def save_feature_space(sample_size):\n",
    "    for arch in MODEL_ARCHITECTURES:\n",
    "        for dataset in DATASETS:\n",
    "            dirname = f\"{arch}_{dataset}\"\n",
    "            train_path = os.path.join(RESULT_DIR, \"feature_space_train\", dirname)\n",
    "            tsne_path = os.path.join(RESULT_DIR, \"tsne\", dirname)\n",
    "            test_path = os.path.join(RESULT_DIR, \"feature_space_test\", dirname)\n",
    "            preds_path = os.path.join(RESULT_DIR, \"predictions_test_all_labels\", dirname)\n",
    "            tac_path = os.path.join(RESULT_DIR, \"tac_activations\", dirname)\n",
    "            \n",
    "            for path in [train_path, tsne_path, test_path, preds_path, tac_path]:\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "\n",
    "            # Testsets in record dict have the target class filtered out, we also need a version with the target class\n",
    "            testset_clean = record_dict[arch][dataset][\"prototype\"][\"test_transformed\"]\n",
    "            testset_clean_with_target_class = get_dataset(dataset, train=False, transforms=TRANSFORM_DICT[f\"{dataset}_test_transformed\"])\n",
    "\n",
    "            model_clean = record_dict[arch][dataset][\"prototype\"][\"model\"]\n",
    "            save_clean_test_preds_all_labels(\"prototype.pt\", model_clean, testset_clean_with_target_class, preds_path, sample_size=sample_size)\n",
    "\n",
    "            for atk in tqdm(ATTACKS, desc=f\"Generating feature space for {arch}, {dataset}\"):\n",
    "                atk_record = record_dict[arch][dataset][atk]\n",
    "\n",
    "                # DFBA is data-free, it does not have a poisoned trainset\n",
    "                if atk == \"dfba\":\n",
    "                    model_bd = atk_record[\"model\"]\n",
    "                    testset_bd = atk_record[\"test_transformed\"]\n",
    "                    save_clean_test_preds_all_labels(f\"{atk}.pt\", model_bd, testset_clean_with_target_class, preds_path, sample_size=sample_size)\n",
    "                    save_test_feature_space(f\"{atk}.pt\", model_bd, testset_clean, testset_bd, test_path, sample_size=sample_size)\n",
    "                    save_tac_activations(f\"{atk}.pt\", model_clean, model_bd, testset_clean, testset_bd, tac_path, sample_size=sample_size)\n",
    "                    continue\n",
    "                \n",
    "                for pr, record in atk_record.items():\n",
    "                    model_bd = record[\"model\"]\n",
    "                    trainset_bd = record[\"train_transformed\"]\n",
    "                    testset_bd = record[\"test_transformed\"]\n",
    "                    save_clean_test_preds_all_labels(f\"{atk}_p{pr}.pt\", model_bd, testset_clean_with_target_class, preds_path, sample_size=sample_size)\n",
    "                    save_train_feature_space(f\"{atk}_p{pr}.pt\", model_bd, trainset_bd, train_path, sample_size=sample_size)\n",
    "                    save_tsne(f\"{atk}_p{pr}\", trainset_bd, train_path, tsne_path)\n",
    "                    save_test_feature_space(f\"{atk}_p{pr}.pt\", model_bd, testset_clean, testset_bd, test_path, sample_size=sample_size)\n",
    "                    save_tac_activations(f\"{atk}_p{pr}.pt\", model_clean, model_bd, testset_clean, testset_bd, tac_path, sample_size=sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa616d",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a28ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = get_sample_size(\"model\")\n",
    "save_feature_space(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffb8fd",
   "metadata": {},
   "source": [
    "## Stealthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_table(attacks, metrics):\n",
    "    table = pd.DataFrame(data=np.full((len(attacks), len(metrics)), None), index=attacks, columns=metrics)\n",
    "    table.columns.name = \"Attack\"\n",
    "\n",
    "    return table\n",
    "\n",
    "def get_model_pr_combinations(benign_and_attacks):\n",
    "    combinations = []\n",
    "\n",
    "    for key in benign_and_attacks:\n",
    "        if key in [\"prototype\", \"dfba\"]:\n",
    "            combinations.append((key, lambda _: None))\n",
    "            continue\n",
    "        \n",
    "        for pr_function in POISON_RATES:\n",
    "            combinations.append((key, pr_function))\n",
    "    \n",
    "    return combinations\n",
    "\n",
    "# Create table that evaluates combinations of model architecture, poison rate and 2 metrics; used for performance, feature-space stealthiness and parameter-space stealthiness \n",
    "def init_combination_table(rows, metrics):\n",
    "    # Create list of (dataset, metric) combinations\n",
    "    columns = []\n",
    "    combinations = list(product(DATASETS, metrics))\n",
    "\n",
    "    # Add a column for each combination\n",
    "    for dataset, metric in combinations:\n",
    "        columns.append(f\"{metric}__{dataset}\")\n",
    "    \n",
    "    table = init_table(rows, columns)\n",
    "\n",
    "    return table, combinations, columns\n",
    "\n",
    "def metric_over_batches(metric, dataset1, dataset2):\n",
    "    dl1 = torch.utils.data.DataLoader(dataset1, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    dl2 = torch.utils.data.DataLoader(dataset2, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    metric_vals = []\n",
    "    batch_weights = [] # Compute weighted average since last batch may be smaller\n",
    "    \n",
    "    for (in_batch1, _), (in_batch2, _) in zip(iter(dl1), iter(dl2)):\n",
    "        assert(len(in_batch1) == len(in_batch2))\n",
    "        batch_weights.append(len(in_batch1))\n",
    "        metric_vals.append(metric(in_batch1, in_batch2))\n",
    "\n",
    "    return np.average(metric_vals, weights=batch_weights)\n",
    "\n",
    "def input_stealth_eval(record_dict, pr_function, sample_size=None, split=\"test\"):\n",
    "    METRIC_DICT = {\n",
    "        \"l1\": l1_distance,\n",
    "        \"l2\": l2_distance,\n",
    "        \"linf\": linf_distance,\n",
    "        \"MSE\": MSE,\n",
    "        \"PSNR\": PSNR,\n",
    "        \"SSIM\": SSIM,\n",
    "        \"LPIPS\": LPIPS,\n",
    "        \"IS\": IS,\n",
    "        \"pHash\": pHash,\n",
    "        \"SAM\": SAM,\n",
    "    }\n",
    "\n",
    "    benign_and_attacks = list(record_dict.keys())\n",
    "    attacks = benign_and_attacks.copy()\n",
    "    attacks.remove(\"prototype\")\n",
    "    input_stealth_table = init_table(benign_and_attacks, METRIC_DICT.keys())\n",
    "    dataset = record_dict[\"prototype\"][split]\n",
    "\n",
    "    # Make sure all poisoned datasets have the same poison indices\n",
    "    if split == \"train\":\n",
    "        atk_baseline = attacks[0]\n",
    "        poison_lookup_compare = record_dict[atk_baseline][pr_function(atk_baseline)][\"train\"].poison_lookup\n",
    "\n",
    "        for atk in attacks[1:]:\n",
    "            pr = pr_function(atk_baseline)\n",
    "            trainset = record_dict[atk][pr][\"train\"]\n",
    "            \n",
    "            if not np.all(trainset.poison_lookup == poison_lookup_compare):\n",
    "                raise Exception(f\"Not all attacks have the same poisoned indices\")\n",
    "            \n",
    "        poison_indices = np.argwhere(poison_lookup_compare).squeeze()\n",
    "    else: # All samples are poisoned in test dataset\n",
    "        poison_indices = range(len(dataset))\n",
    "\n",
    "    if sample_size:\n",
    "        poison_indices = np.random.choice(poison_indices, size=sample_size, replace=False)\n",
    "    \n",
    "    dataset = torch.utils.data.Subset(dataset, poison_indices)\n",
    "\n",
    "    for key in tqdm(benign_and_attacks, desc=f\"Evaluating input-space stealthiness of poisoned {split}sets\"):\n",
    "        if key == \"prototype\":\n",
    "            dataset_bd = dataset\n",
    "        elif key == \"dfba\":\n",
    "            dataset_bd = torch.utils.data.Subset(record_dict[key][split], poison_indices)\n",
    "        else:\n",
    "            pr = pr_function(key)\n",
    "            dataset_bd = torch.utils.data.Subset(record_dict[key][pr][split], poison_indices)\n",
    "            \n",
    "        for metric, metric_func in METRIC_DICT.items():\n",
    "            measurement = metric_over_batches(metric_func, dataset, dataset_bd)\n",
    "            input_stealth_table.at[key, metric] = measurement\n",
    "\n",
    "    return input_stealth_table\n",
    "\n",
    "def feature_stealth_eval(record_dict):\n",
    "    atk_pr_tuples = get_model_pr_combinations(ATTACKS)\n",
    "    rows = [f\"{model}_p{pr_function(model)}\" for model, pr_function in atk_pr_tuples]\n",
    "    feature_stealth_table, combinations, columns = init_combination_table(rows, [\"SS\", \"DSWD\"])\n",
    "   \n",
    "    for i, (dataset, metric) in enumerate(combinations):\n",
    "        for j, (atk, pr_function) in tqdm(enumerate(atk_pr_tuples), total=len(atk_pr_tuples), desc=f\"Evaluating {metric} metric on {dataset} models\"):\n",
    "            # Cannot evaluate SS for DFBA since it does not have poisoned training data\n",
    "            if metric == \"SS\" and atk == \"dfba\":\n",
    "                continue\n",
    "            \n",
    "            pr = pr_function(atk)\n",
    "\n",
    "            if pr:\n",
    "                dict = record_dict[dataset][atk][pr]\n",
    "            else:\n",
    "                dict = record_dict[dataset][atk]\n",
    "            \n",
    "            exp_id = f\"{MODEL_ARCH}_{dataset}\"\n",
    "            atk_id = atk if atk == \"dfba\" else f\"{atk}_p{pr}\"\n",
    "\n",
    "            if metric == \"SS\":\n",
    "                tsne_path = os.path.join(RESULT_DIR, \"tsne\", exp_id, atk_id, \"embedding.pt\")\n",
    "                tsne_dict = torch.load(tsne_path, weights_only=False)\n",
    "                feature_stealth_table.at[rows[j], columns[i]] = SS(tsne_dict[\"features_benign\"], tsne_dict[\"features_poisoned\"])\n",
    "            else:\n",
    "                model = dict[\"model\"]\n",
    "                feature_save_path = os.path.join(RESULT_DIR, \"feature_space_test\", exp_id, f\"{atk_id}.pt\")\n",
    "                feature_stealth_table.at[rows[j], columns[i]] = DSWD(model, feature_save_path)\n",
    "                \n",
    "    return feature_stealth_table\n",
    "\n",
    "def parameter_stealth_eval(record_dict):\n",
    "    benign_and_attacks = list(record_dict[DATASET].keys())\n",
    "    atk_pr_tuples = get_model_pr_combinations(benign_and_attacks)\n",
    "    rows = [f\"{model}_p{pr_function(model)}\" for model, pr_function in atk_pr_tuples]\n",
    "    parameter_stealth_table, combinations, columns = init_combination_table(rows, [\"UCLC\", \"TAC\"])\n",
    "   \n",
    "    for i, (dataset, metric) in enumerate(combinations):\n",
    "        for j, (atk, pr_function) in tqdm(enumerate(atk_pr_tuples), total=len(atk_pr_tuples), desc=f\"Evaluating {metric} metric on {dataset} models\"):\n",
    "            # Cannot evaluate TAC for benign model since it does not have a trigger\n",
    "            if metric == \"TAC\" and atk == \"prototype\":\n",
    "                continue\n",
    "            \n",
    "            pr = pr_function(atk)\n",
    "\n",
    "            if pr:\n",
    "                dict = record_dict[dataset][atk][pr]\n",
    "            else:\n",
    "                dict = record_dict[dataset][atk]\n",
    "\n",
    "            model = dict[\"model\"]\n",
    "  \n",
    "            if metric == \"UCLC\":\n",
    "                uclc = UCLC(model)\n",
    "                parameter_stealth_table.at[rows[j], columns[i]] = uclc.max().item()\n",
    "            else:\n",
    "                exp_id = f\"{MODEL_ARCH}_{dataset}\"\n",
    "                atk_id = atk if atk == \"dfba\" else f\"{atk}_p{pr}\"\n",
    "                feature_save_path = os.path.join(RESULT_DIR, \"tac_activations\", exp_id, f\"{atk_id}.pt\")\n",
    "                tac = TAC(feature_save_path)\n",
    "                parameter_stealth_table.at[rows[j], columns[i]] = tac.max().item()\n",
    "                \n",
    "    return parameter_stealth_table\n",
    "\n",
    "def new_metric_eval(record_dict):\n",
    "    atk_pr_tuples = get_model_pr_combinations(ATTACKS)\n",
    "    rows = [f\"{model}_p{pr_function(model)}\" for model, pr_function in atk_pr_tuples]\n",
    "    new_metric_table, combinations, columns = init_combination_table(rows, [\"CDBI\", \"TUP\"])\n",
    "   \n",
    "    for i, (dataset, metric) in enumerate(combinations):\n",
    "        for j, (atk, pr_function) in tqdm(enumerate(atk_pr_tuples), total=len(atk_pr_tuples), desc=f\"Evaluating {metric} metric on {dataset} models\"):\n",
    "            # Cannot evaluate CDBI for DFBA since it does not have poisoned training data\n",
    "            if atk == \"dfba\" and metric == \"CDBI\":\n",
    "                continue\n",
    "\n",
    "            pr = pr_function(atk)\n",
    "\n",
    "            if pr:\n",
    "                dict = record_dict[dataset][atk][pr]\n",
    "            else:\n",
    "                dict = record_dict[dataset][atk]\n",
    "\n",
    "            exp_id = f\"{MODEL_ARCH}_{dataset}\"\n",
    "            atk_id = atk if atk == \"dfba\" else f\"{atk}_p{pr}\"\n",
    "            \n",
    "            if metric == \"CDBI\":\n",
    "                tsne_path = os.path.join(RESULT_DIR, \"tsne\", exp_id, atk_id, \"embedding.pt\")\n",
    "                tsne_dict = torch.load(tsne_path, weights_only=False)\n",
    "                new_metric_table.at[rows[j], columns[i]] = CDBI(tsne_dict[\"features_benign\"], \n",
    "                                                               tsne_dict[\"features_poisoned\"], \n",
    "                                                               tsne_dict[\"gt_labels_poisoned\"])\n",
    "            else:\n",
    "                model = dict[\"model\"]\n",
    "                tac_save_path = os.path.join(RESULT_DIR, \"tac_activations\", exp_id, f\"{atk_id}.pt\")\n",
    "                new_metric_table.at[rows[j], columns[i]] = TUP(tac_save_path, model)\n",
    "            \n",
    "    return new_metric_table\n",
    "\n",
    "def compare_poisoned_images(record_dict, pr_function, train=False, transformed=False, index=0, fig_height=3, save_suffix=\"\", save=True):\n",
    "    benign_and_attacks = list(record_dict.keys())\n",
    "    fig, ax = plt.subplots(1, len(benign_and_attacks))\n",
    "    split = \"train\" if train else \"test\"\n",
    "\n",
    "    # Save individual images as files\n",
    "    if save:\n",
    "        save_path = os.path.join(RESULT_DIR, f\"poison_images_{split}\", f\"{MODEL_ARCH}_{DATASET}\")\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    split += \"_transformed\" if transformed else \"\"\n",
    "\n",
    "    for i, key in enumerate(benign_and_attacks):\n",
    "        if key in [\"prototype\", \"dfba\"]:\n",
    "            dataset = record_dict[key][split]\n",
    "        else:\n",
    "            pr = pr_function(key)\n",
    "            dataset = record_dict[key][pr][split]\n",
    "\n",
    "        img, _ = dataset.__getitem__(index)\n",
    "        ax[i].imshow(img.permute(1, 2, 0))\n",
    "        ax[i].set_title(key)\n",
    "        ax[i].axis(\"off\")\n",
    "\n",
    "        if save:\n",
    "            to_pil = T.ToPILImage()\n",
    "            img = to_pil(img)\n",
    "            img.save(os.path.join(save_path, f\"{key}{save_suffix}.png\"))\n",
    "\n",
    "    fig.suptitle(\"Comparison of poisoned images for different attacks\")\n",
    "    fig.set_figheight(fig_height)\n",
    "    fig.set_figwidth(fig_height * len(benign_and_attacks))\n",
    "\n",
    "def results_to_csv(table, result_type, model_arch, dataset):\n",
    "    path = os.path.join(RESULT_DIR, \"tables\", f\"{result_type}_{model_arch}\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    table.to_csv(os.path.join(path, f\"{dataset}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11efbe9d",
   "metadata": {},
   "source": [
    "## Performance (Backdoor Accuracy and Attack Success Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ba(feature_dict, testset_clean):\n",
    "    predictions = feature_dict[\"predictions_clean\"].numpy()\n",
    "    indices = feature_dict[\"indices\"]\n",
    "    labels = np.array(testset_clean.targets)[indices]\n",
    "\n",
    "    return np.mean(predictions == labels) * 100\n",
    "\n",
    "def calculate_asr(feature_dict, testset_bd):\n",
    "    predictions = feature_dict[\"predictions_bd\"].numpy()\n",
    "    indices = feature_dict[\"indices\"]\n",
    "    labels = testset_bd.poisoned_labels[indices]\n",
    "\n",
    "    return np.mean(predictions == labels) * 100\n",
    "\n",
    "def performance_eval(record_dict):\n",
    "    benign_and_attacks = list(record_dict[DATASET].keys())\n",
    "    atk_pr_tuples = get_model_pr_combinations(benign_and_attacks)\n",
    "    rows = [f\"{model}_p{pr_function(model)}\" for model, pr_function in atk_pr_tuples]\n",
    "    performance_table, combinations, columns = init_combination_table(rows, [\"BA\", \"ASR\"]) \n",
    "   \n",
    "    for i, (dataset, metric) in enumerate(combinations):\n",
    "        testset_clean = get_dataset(dataset, train=False, transforms=\"test_transformed\")\n",
    "        \n",
    "        for j, (atk, pr_function) in tqdm(enumerate(atk_pr_tuples), desc=f\"Evaluating {metric} metric on {dataset} models\"):\n",
    "            pr = pr_function(atk)\n",
    "            \n",
    "            if pr:\n",
    "                dict = record_dict[dataset][atk][pr]\n",
    "            else:\n",
    "                dict = record_dict[dataset][atk]\n",
    "\n",
    "            exp_id = f\"{MODEL_ARCH}_{dataset}\"\n",
    "            atk_id = atk if atk in [\"dfba\", \"prototype\"] else f\"{atk}_p{pr}\"\n",
    "\n",
    "            # Calculate benign accuracy for all models\n",
    "            if metric == \"BA\":\n",
    "                ba_preds_path = os.path.join(RESULT_DIR, \"predictions_test_all_labels\", exp_id, f\"{atk_id}.pt\")\n",
    "                ba_preds_preds_dict = torch.load(ba_preds_path, weights_only=False)\n",
    "                performance_table.at[rows[j], columns[i]] = calculate_ba(ba_preds_preds_dict, testset_clean)\n",
    "            # Calculate attack success rate only for backdoored models\n",
    "            elif metric == \"ASR\" and atk != \"prototype\":\n",
    "                asr_preds_path = os.path.join(RESULT_DIR, \"feature_space_test\", exp_id, f\"{atk_id}.pt\")\n",
    "                asr_preds_dict = torch.load(asr_preds_path, weights_only=False)\n",
    "                testset_bd = dict[\"test_transformed\"]\n",
    "                performance_table.at[rows[j], columns[i]] = calculate_asr(asr_preds_dict, testset_bd)\n",
    "                \n",
    "    return performance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7241d",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate testsets\n",
    "input_stealth_table_test = input_stealth_eval(record_dict[MODEL_ARCH][DATASET], DEFAULT_POISON_RATE, sample_size=get_sample_size(\"input\"))\n",
    "\n",
    "# Evaluate trainsets for Adap-Patch and Adap-Blend\n",
    "input_stealth_table_train_adap = None\n",
    "adap = list_intersection(ATTACKS, [\"adaptive_patch\", \"adaptive_blend\"])\n",
    "\n",
    "if adap != []:\n",
    "    benign_and_adap = [\"prototype\"] + adap\n",
    "    record_dict_adap = dict_subset(record_dict[MODEL_ARCH][DATASET], benign_and_adap)\n",
    "    input_stealth_table_train_adap = input_stealth_eval(record_dict_adap, DEFAULT_POISON_RATE, split=\"train\", sample_size=get_sample_size(\"input\"))\n",
    "\n",
    "# Evaluate trainset for Narcissus\n",
    "narcissus = list_intersection(ATTACKS, [\"narcissus\"])\n",
    "input_stealth_table_train_narcissus = None\n",
    "\n",
    "if narcissus != []:\n",
    "    benign_and_narcissus = [\"prototype\"] + narcissus\n",
    "    record_dict_narcissus = dict_subset(record_dict[MODEL_ARCH][DATASET], benign_and_narcissus)\n",
    "    input_stealth_table_train_narcissus = input_stealth_eval(record_dict_narcissus, DEFAULT_POISON_RATE, split=\"train\", sample_size=get_sample_size(\"input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532539d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_stealth_table = feature_stealth_eval(record_dict[MODEL_ARCH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_stealth_table = parameter_stealth_eval(record_dict[MODEL_ARCH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee846a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metric_table = new_metric_eval(record_dict[MODEL_ARCH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ff48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_eval_table = performance_eval(record_dict[MODEL_ARCH])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76c21e",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62454ddf",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "results_to_csv(performance_eval_table, \"performance\", MODEL_ARCH, DATASET)\n",
    "performance_eval_table.fillna(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572fde06",
   "metadata": {},
   "source": [
    "## Stealthiness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac8662",
   "metadata": {},
   "source": [
    "### Input-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the specified attacks, copy the rows of the train table to the test table:\n",
    "def merge_input_tables(test, train, atks):\n",
    "    for atk in atks:\n",
    "        # Get index of testset result to place trainset result above it\n",
    "        row_headers = list(test.index)\n",
    "        idx = row_headers.index(atk)\n",
    "\n",
    "        # Rename testset result by explicitly specifying \"Test\"\n",
    "        test.rename(index={atk : f\"{atk} test\"}, inplace=True)\n",
    "\n",
    "        # Get correct row from train table and insert it into the merged table\n",
    "        train_row = train[train.index == atk]\n",
    "        test = pd.concat([test.iloc[:idx], \n",
    "                          train_row, \n",
    "                          test.iloc[idx:]])\n",
    "    \n",
    "        # Rename testset result by explicitly specifying \"Train\"\n",
    "        test.rename(index={atk : f\"{atk} train\"}, inplace=True)\n",
    "\n",
    "    return test\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "input_stealth_table = merge_input_tables(input_stealth_table_test, input_stealth_table_train_adap, adap)\n",
    "input_stealth_table = merge_input_tables(input_stealth_table, input_stealth_table_train_narcissus, narcissus)\n",
    "\n",
    "# Skip benign row when saving to csv\n",
    "results_to_csv(input_stealth_table[input_stealth_table.index != \"prototype\"], \"input_stealth\", MODEL_ARCH, DATASET)\n",
    "\n",
    "input_stealth_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a33f218",
   "metadata": {},
   "source": [
    "### Feature-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepend placeholder row to feature stealth table to make its shape consistent with performance and parameter stealth tables\n",
    "# This is necessary for converting the csv files to LaTeX tables\n",
    "def prepend_placeholder(table):\n",
    "    cols = table.columns\n",
    "    n_cols = len(table.columns)\n",
    "    placeholder =  pd.DataFrame(\n",
    "        [[None] * n_cols],\n",
    "        columns=cols,\n",
    "        index=[\"PLACEHOLDER\"]\n",
    "    )\n",
    "    \n",
    "    return pd.concat([placeholder, table])\n",
    "\n",
    "results_to_csv(prepend_placeholder(feature_stealth_table), \"feature_stealth\", MODEL_ARCH, DATASET)\n",
    "\n",
    "feature_stealth_table.fillna(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49238b",
   "metadata": {},
   "source": [
    "### Parameter-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_csv(parameter_stealth_table, \"parameter_stealth\", MODEL_ARCH, DATASET)\n",
    "parameter_stealth_table.fillna(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ef3e4",
   "metadata": {},
   "source": [
    "### New metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661af76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_csv(prepend_placeholder(new_metric_table), \"new_metrics\", MODEL_ARCH, DATASET)\n",
    "new_metric_table.fillna(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989b419",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8f1ca",
   "metadata": {},
   "source": [
    "### Testing dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b752cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_poisoned_images(record_dict[MODEL_ARCH][DATASET], DEFAULT_POISON_RATE, train=False, transformed=False, index=IMG_INDEX_DICT[DATASET][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee38c7b",
   "metadata": {},
   "source": [
    "### Training dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e406810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_poisoned_images_train(atks, record_dict_atks):\n",
    "    contains_trigger = lambda trainset: np.logical_or(trainset.poison_lookup, trainset.cross_lookup) \n",
    "\n",
    "    trigger_lookups = [contains_trigger(record_dict_atks[atk][DEFAULT_POISON_RATE(atk)][\"train\"]) for atk in atks if atk != \"prototype\"]\n",
    "    contains_trigger_all = np.logical_and.reduce(trigger_lookups)\n",
    "    trigger_indices = np.argwhere(contains_trigger_all).squeeze()\n",
    "    \n",
    "    for i, idx in enumerate(IMG_INDEX_DICT[DATASET][\"train\"]):\n",
    "        compare_poisoned_images(record_dict_atks, DEFAULT_POISON_RATE, train=True, index=trigger_indices[idx], save_suffix=i, save=False)\n",
    "\n",
    "if adap != [] or narcissus != []:\n",
    "    train_subset = [\"prototype\"] + adap + narcissus\n",
    "    record_dict_train = dict_subset(record_dict[MODEL_ARCH][DATASET], train_subset)\n",
    "    compare_poisoned_images_train(train_subset, record_dict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b8932d",
   "metadata": {},
   "source": [
    "### TAC plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64237cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAC_comparison(record_dict, MODEL_ARCH, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec098642",
   "metadata": {},
   "source": [
    "# Extra input-space experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64255f6",
   "metadata": {},
   "source": [
    "## SSIM on BadNets vs DFBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49861ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "testset_clean = record_dict[MODEL_ARCH][DATASET][\"prototype\"][\"test\"]\n",
    "img_clean, _ = testset_clean[index]\n",
    "\n",
    "testset_badnets = record_dict[MODEL_ARCH][DATASET][\"badnet\"][0.05][\"test\"]\n",
    "img_badnets, _ = testset_badnets[index]\n",
    "\n",
    "testset_dfba = record_dict[MODEL_ARCH][DATASET][\"dfba\"][\"test\"]\n",
    "img_dfba, _ = testset_dfba[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,2, sharey=True)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "atks = [\"BadNets\", \"DFBA\"]\n",
    "\n",
    "for i, img in enumerate([img_badnets, img_dfba]):\n",
    "    _, ssim = structural_similarity(img.numpy(), img_clean.numpy(), data_range=1, channel_axis=0, full=True)\n",
    "    plot = ax[i].imshow(ssim.mean(axis=0), cmap=\"gray\", vmin=0, vmax=1)\n",
    "    ax[i].set_title(atks[i])\n",
    "\n",
    "cax = fig.add_axes([ax[1].get_position().x1+0.06, ax[1].get_position().y0, 0.02, ax[1].get_position().height])\n",
    "cbar = plt.colorbar(plot, cax=cax, ticks=[0,1], label=\"SSIM\")\n",
    "\n",
    "if DATASET == \"cifar10\":\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"ssim_badnets_dfba.png\"), bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c66931",
   "metadata": {},
   "source": [
    "## SAM on BadNets, DFBA, WaNet and Bpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44267c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_wanet = record_dict[MODEL_ARCH][DATASET][\"wanet\"][0.05][\"test\"]\n",
    "testset_bpp = record_dict[MODEL_ARCH][DATASET][\"bpp\"][0.05][\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc151de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(testset_clean)\n",
    "atks = [\"BadNets\", \"DFBA\", \"WaNet\", \"BppAttack\"]\n",
    "avg_sam = torch.zeros([len(atks)] + list(IMG_SIZE_DICT[DATASET]))\n",
    "\n",
    "for i in tqdm(range(n_samples)):\n",
    "    img_clean, _ = testset_clean[i]\n",
    "    img_badnets, _ = testset_badnets[i]\n",
    "    img_dfba, _= testset_dfba[i]\n",
    "    img_wanet, _ = testset_wanet[i]\n",
    "    img_bpp, _ = testset_bpp[i]\n",
    "    \n",
    "    for j, img in enumerate([img_badnets, img_dfba, img_wanet, img_bpp]):\n",
    "        sam = spectral_angle_mapper(img.unsqueeze(0).clamp(1e-8, 1), img_clean.unsqueeze(0).clamp(1e-8, 1), reduction='none').squeeze()\n",
    "        avg_sam[j] += sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec528bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5)\n",
    "\n",
    "for row_idx in range(2):\n",
    "    sam1 = avg_sam[row_idx * 2] / n_samples\n",
    "    sam2 = avg_sam[row_idx * 2 + 1] / n_samples\n",
    "    max_sam = max(sam1.max(), sam2.max())\n",
    "\n",
    "    for col_idx, sam in enumerate([sam1, sam2]):\n",
    "        plot = ax[row_idx][col_idx].imshow(sam, cmap=\"gray\", vmin=0, vmax=max_sam)\n",
    "        ax[row_idx][col_idx].set_title(atks[row_idx * 2 + col_idx])\n",
    "\n",
    "    ax2 = ax[row_idx][1]\n",
    "    cax = fig.add_axes([ax2.get_position().x1+0.07, ax2.get_position().y0, 0.02, ax2.get_position().height])\n",
    "    cbar = plt.colorbar(plot, cax=cax, label=\"SAM\")\n",
    "\n",
    "if DATASET == \"cifar10\":\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"sam_per_pixel.png\"), bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dbd6e7",
   "metadata": {},
   "source": [
    "## MSE and SSIM on Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_squared_diff_dict = {}\n",
    "avg_ssim_dict = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    avg_squared_diff = torch.zeros((3,) + IMG_SIZE_DICT[dataset])\n",
    "    avg_ssim = torch.zeros((3,) + IMG_SIZE_DICT[dataset])\n",
    "    testset_clean = record_dict[MODEL_ARCH][dataset][\"prototype\"][\"test\"]\n",
    "    testset_blend = record_dict[MODEL_ARCH][dataset][\"blended\"][0.05][\"test\"]\n",
    "    n_samples = len(testset_clean)\n",
    "\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        img_clean, _ = testset_clean[i]\n",
    "        img_blend, _ = testset_blend[i]\n",
    "\n",
    "        squared_diff = np.power(img_blend - img_clean, 2)\n",
    "        _, ssim = structural_similarity(img_blend.numpy(), img_clean.numpy(), data_range=1, channel_axis=0, full=True)\n",
    "        avg_squared_diff += squared_diff\n",
    "        avg_ssim += ssim\n",
    "\n",
    "    avg_squared_diff_dict[dataset] = (avg_squared_diff / n_samples).mean(dim=0)\n",
    "    avg_ssim_dict[dataset] = (avg_ssim / n_samples).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_datasets = len(DATASETS)\n",
    "fig, axs = plt.subplots(n_datasets, 3, squeeze=False)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(9)\n",
    "\n",
    "TRIGGER_DICT = {\n",
    "    \"cifar10\": \"hellokitty_32.png\",\n",
    "    \"cifar100\": \"hellokitty_32.png\",\n",
    "    \"imagenette\": \"hellokitty_80.png\"\n",
    "}\n",
    "\n",
    "DATASET_PPRINT_DICT = {\n",
    "    \"cifar10\": \"CIFAR-10\",\n",
    "    \"cifar100\": \"CIFAR-100\",\n",
    "    \"imagenette\": \"Imagenette\",\n",
    "}\n",
    "\n",
    "# Turn off ticks in plots\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "# Show trigger for each dataset\n",
    "for row_idx, dataset in enumerate(DATASETS):\n",
    "    trigger_path = os.path.join(\"adap\", \"triggers\", TRIGGER_DICT[dataset])\n",
    "    trigger = Image.open(trigger_path)\n",
    "    axs[row_idx][0].imshow(trigger)\n",
    "    axs[row_idx][0].set_ylabel(DATASET_PPRINT_DICT[dataset], rotation=90, size=\"larger\")\n",
    "\n",
    "# Show MSE and SSIM measurements for each dataset\n",
    "for i, (measurement_dict, label) in enumerate([(avg_squared_diff_dict, \"Squared error\"), (avg_ssim_dict, \"SSIM\")]):\n",
    "    max_measurement = max([measurements.max() for measurements in measurement_dict.values()])\n",
    "    min_measurement = max([measurements.min() for measurements in measurement_dict.values()])\n",
    "\n",
    "    for row_idx, dataset in enumerate(DATASETS):\n",
    "        measurements = measurement_dict[dataset]\n",
    "        plot = axs[row_idx][i+1].imshow(measurements, cmap=\"gray\", vmin=min_measurement, vmax=max_measurement)\n",
    "\n",
    "    ax2 = axs[n_datasets-1][i+1]\n",
    "    cax = fig.add_axes([ax2.get_position().x0, ax2.get_position().y0 - 0.05, ax2.get_position().width, 0.02])\n",
    "    cbar = plt.colorbar(plot, cax=cax, label=label, orientation=\"horizontal\")\n",
    "\n",
    "if \"cifar10\" in DATASETS and \"imagenette\" in DATASETS:\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"blend_mse_ssim.png\"), bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66729276",
   "metadata": {},
   "source": [
    "## SAM on each Adap-Patch trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959bd918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code separates the poisoned samples for each trigger\n",
    "# It does not work for the Imagenette dataset, since we changed the way the trigger is selected\n",
    "clean_trainset = record_dict[MODEL_ARCH][DATASET][\"prototype\"][\"train\"]\n",
    "adap_trainset = record_dict[MODEL_ARCH][DATASET][\"adaptive_patch\"][0.05][\"train\"]\n",
    "poison_indices = np.argwhere(adap_trainset.poison_lookup).squeeze()\n",
    "n_poison = len(poison_indices)\n",
    "n_triggers = 4\n",
    "poison_indices_per_trigger = [[] for _ in range(n_triggers)]\n",
    "\n",
    "for i, p in enumerate(poison_indices):\n",
    "    for j in range(n_triggers):\n",
    "        if i < (j + 1) * (n_poison / n_triggers):\n",
    "            poison_indices_per_trigger[j].append(p)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_triggers):\n",
    "    trigger_indices = poison_indices_per_trigger[i]\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    img1, _ = adap_trainset.__getitem__(trigger_indices[0])\n",
    "    img2, _ = adap_trainset.__getitem__(trigger_indices[-1])\n",
    "    ax[0].imshow(img1.permute(1,2,0))\n",
    "    ax[1].imshow(img2.permute(1,2,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa492424",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_names = [\"Phoenix Corner\", \"Firefox\", \"BadNets\", \"Trojan Square\"]\n",
    "sam_table = init_table(trigger_names, [\"MSE\", \"SAM\"])\n",
    "\n",
    "for i, trigger in enumerate(trigger_names):\n",
    "    trigger_indices = poison_indices_per_trigger[i]\n",
    "    clean_dl = torch.utils.data.DataLoader(clean_trainset, batch_sampler=[trigger_indices])\n",
    "    trigger_dl = torch.utils.data.DataLoader(adap_trainset, batch_sampler=[trigger_indices])\n",
    "    clean_images, _ = next(iter(clean_dl))\n",
    "    trigger_images, _ = next(iter(trigger_dl))\n",
    "    sam_table.at[trigger, \"MSE\"] = MSE(clean_images, trigger_images)\n",
    "    sam_table.at[trigger, \"SAM\"] = SAM(clean_images, trigger_images)\n",
    "\n",
    "if DATASET == \"cifar10\":\n",
    "    results_to_csv(sam_table, \"sam_adap-patch\", MODEL_ARCH, DATASET)\n",
    "\n",
    "sam_table"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
